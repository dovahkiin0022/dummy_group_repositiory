{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "hyperparameter_opt.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPYFdbq/d0L3TLk5SuJ07V+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dovahkiin0022/dummy_group_repository/blob/hyperparameter_opt/hyperparameter_opt.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/dovahkiin0022/dummy_group_repository.git\n",
        "!cd dummy_group_repository && git checkout hyperparameter_opt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3iYtPqqun733",
        "outputId": "c36cac96-d709-43be-b1f7-7d0f4c95759c"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'dummy_group_repository'...\n",
            "remote: Enumerating objects: 154, done.\u001b[K\n",
            "remote: Counting objects: 100% (63/63), done.\u001b[K\n",
            "remote: Compressing objects: 100% (34/34), done.\u001b[K\n",
            "remote: Total 154 (delta 36), reused 39 (delta 29), pack-reused 91\u001b[K\n",
            "Receiving objects: 100% (154/154), 8.50 MiB | 18.92 MiB/s, done.\n",
            "Resolving deltas: 100% (52/52), done.\n",
            "Branch 'hyperparameter_opt' set up to track remote branch 'hyperparameter_opt' from 'origin'.\n",
            "Switched to a new branch 'hyperparameter_opt'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Hyperparameter Tuning**\n",
        "\n",
        "Hyperparameter tuning is an optimization problem, like model training.\n",
        "\n",
        "List of hyperparameters for a regression model:\n",
        "\n",
        "1. "
      ],
      "metadata": {
        "id": "KHi2kwIGeY4Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Install Dependencies"
      ],
      "metadata": {
        "id": "i1OGk7h-jdba"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_absolute_percentage_error\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "qeJZHaP6jc60"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Load Dataset\n",
        "\n",
        "*--> the code for loading the data will be added here after preprocessing.*"
      ],
      "metadata": {
        "id": "L7vEfQCIjiax"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X, y"
      ],
      "metadata": {
        "id": "mrycZnUUkSfg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# split as train/test\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
        "                                               test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "Bl2FgxNYkJDn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Model\n",
        "\n",
        "*--> After deciding on the model and the features (input-output), the code for the model will be added here.*"
      ],
      "metadata": {
        "id": "PHzRS_lKiNmI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import ...\n",
        "model = ...\n",
        "\n",
        "def train_model():\n",
        "\n",
        "  loss = \n",
        " return loss"
      ],
      "metadata": {
        "id": "dF7JwzZdlKiD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define hyperparameters to be tuned\n",
        "params = {'n_ch': 16, 'width': 5, 'n_conv': 4}"
      ],
      "metadata": {
        "id": "0Jz2AZm6lWPz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Grid Search\n",
        "Define a search space as a grid ('param_grid') of hyperparameter values and evaluate every position in the grid."
      ],
      "metadata": {
        "id": "rL0qD-_tiUJ7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "boYIIit6dzpt"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "train_errors = []\n",
        "\n",
        "def grid_search(**params):\n",
        "\n",
        "  # Define cross validation method if you prefer. Otherwise, it is a number (currently 10).\n",
        "  gs = GridSearchCV(model, params, scoring='neg_mean_absolute_percentage_error', \n",
        "                    n_jobs=-1, cv=10)\n",
        "\n",
        "  # Perform Grid Search using train input and output\n",
        "  result = gs.fit(X_train, y_train)\n",
        "\n",
        "  print('Best Score: %0.4f' % result.best_score_)\n",
        "  print('Best Hyperparameters: %s' % result.best_params_)\n",
        "\n",
        "  # Return the best hyperparameters\n",
        "  return result.best_params_"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_errors, test_errors = [], []\n",
        "\n",
        "for m in np.linspace(1, len(X_train), len(X_train):\n",
        "\n",
        "  model = model(**result.best_params_)\n",
        "  model.fit(X_train, y_train)\n",
        "\n",
        "  y_predict_train = model.predict(X_train[:m])\n",
        "  y_predict_test = model.predict(X_test)\n",
        "  \n",
        "  train_errors.append(mean_absolute_percentage_error(y_train[:m], y_predict_train))\n",
        "  test_errors.append(mean_absolute_percentage_error(y_test, y_predict_test))\n",
        "\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "\n",
        "ax.plot(np.linspace(1, len(X_train), len(X_train), train_errors, '-', linewidth=3,\n",
        "        label=\"Training score\")\n",
        "ax.plot(np.linspace(1, len(X_test), len(X_test), test_errors, '-', linewidth=3,\n",
        "        label=\"Test score\")\n",
        "\n",
        "ax.xlabel(\"Training Set Size\")\n",
        "ax.ylabel(\"MAPE\")\n",
        "ax.legend(loc=\"best\")\n",
        "\n",
        "plot.show()"
      ],
      "metadata": {
        "id": "wEp5zSuml6vd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Random Search\n",
        "Define a search space as a bounded domain of hyperparameter values and randomly sample points in that domain."
      ],
      "metadata": {
        "id": "VSw5nnw2kiZh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "def random_search():\n",
        "\n",
        "  #Define cross validation method if you prefer. Otherwise, it is a number (currently 10).\n",
        "  rs = RandomizedSearchCV(model, params, scoring='neg_mean_absolute_percentage_error', \n",
        "                          n_jobs=-1, cv=10)\n",
        "\n",
        "  # Perform Random Search using train input and output\n",
        "  result = rs.fit(X_train, y_train)\n",
        "\n",
        "  print('Best Score: %0.4f' % result.best_score_)\n",
        "  print('Best Hyperparameters: %s' % result.best_params_)\n",
        "\n",
        "  # Return the best hyperparameters\n",
        "  return result.best_params_"
      ],
      "metadata": {
        "id": "ORHAhjC9k4qk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Genetic Algorithm"
      ],
      "metadata": {
        "id": "kH1RJ7JIcwe3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Parameters required to be defined for each problem according to paper (https://arxiv.org/pdf/2106.06158.pdf):\n",
        "1. num_generations: The number of generations/iterations.\n",
        "2. sol_per_pop: The number of solutions/chromosomes/indi-\n",
        "viduals in the population (i.e. population size).\n",
        "3. num_parents_mating: The number of solutions to be selected from the population as parents for mating and producing the offspring.\n",
        "4. num_genes: The number of genes in each solution.\n",
        "5. fitness_func: The fitness function."
      ],
      "metadata": {
        "id": "1l6Yfr8rdRkT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install pygad"
      ],
      "metadata": {
        "id": "v36vXE4vdGRa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fitness function evaluates the performance of the mutations and the operations in genetic algorithm. To do so, a metric (value) must be defined. This value can be the loss value during training of the model.\n",
        "\n",
        "Since the aim is to minimize the loss during training and to increase the fitness value in the genetic algorithm, in order not to get mathematical error in case of very low loss values, the fitness value can be defined as 1/loss. "
      ],
      "metadata": {
        "id": "_v15z3B8ddaX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pygad\n",
        "\n",
        "def fitness_func(solution, solution_idx):\n",
        "  loss = train_model(**params)\n",
        "  fitness=1/loss.item()\n",
        "  return fitness\n",
        "\n",
        "fitness_function = fitness_func\n",
        "\n",
        "num_generations = 5\n",
        "num_parents_mating = 4\n",
        "\n",
        "sol_per_pop = 5\n",
        "num_genes = 3\n",
        "\n",
        "init_range_low = 5\n",
        "init_range_high = 10\n",
        "\n",
        "parent_selection_type = \"sss\"\n",
        "keep_parents = 1\n",
        "\n",
        "crossover_type = \"uniform\"\n",
        "\n",
        "mutation_type = \"random\"\n",
        "mutation_percent_genes = 40\n",
        "\n",
        "# define the range of each variable if necessary\n",
        "gene_space = [{'low': 1, 'high': 64}, {'low': 1, 'high': 5}, {'low': 1, 'high': 10}]"
      ],
      "metadata": {
        "id": "8c4ZFCpTfJf2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ga_instance = pygad.GA(num_generations=num_generations,\n",
        "                       num_parents_mating=num_parents_mating,\n",
        "                       fitness_func=fitness_function,\n",
        "                       sol_per_pop=sol_per_pop,\n",
        "                       num_genes=num_genes,\n",
        "                       init_range_low=init_range_low,\n",
        "                       init_range_high=init_range_high,\n",
        "                       parent_selection_type=parent_selection_type,\n",
        "                       keep_parents=keep_parents,\n",
        "                       crossover_type=crossover_type,\n",
        "                       mutation_type=mutation_type,\n",
        "                       mutation_percent_genes=mutation_percent_genes,\n",
        "                       gene_space=gene_space,\n",
        "                       gene_type=int\n",
        "                       )\n",
        "\n",
        "ga_instance.run()"
      ],
      "metadata": {
        "id": "vUepMNHSeyNO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the best parameters, fitness value and the index of the generation for the best parameters\n",
        "solution, solution_fitness, solution_idx = ga_instance.best_solution()\n",
        "\n",
        "print('Best Score: %0.4f' % solution_fitness)\n",
        "print('Best Hyperparameters: %s' % solution)"
      ],
      "metadata": {
        "id": "SV8K5A-Pe3-s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plot the performance of genetic lagorithm during iterations\n",
        "fig = ga_instance.plot_result()"
      ],
      "metadata": {
        "id": "IeJ7ibdggbQy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Bayesian Optimization"
      ],
      "metadata": {
        "id": "3uw8-SNbhexw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install bayesian-optimization"
      ],
      "metadata": {
        "id": "np4ZFJbfggWs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from bayes_opt import BayesianOptimization\n",
        "\n",
        "def loss(solution, solution_idx):\n",
        "  loss = train_model(**params)\n",
        "  return 1/loss.item()\n",
        "\n",
        "def bayesian_opt():\n",
        "  # Define range for the model parameters to be optimized\n",
        "  pbounds = {'E':(1e6,70e6), 'nu':(0, 0.5), 'C1':(5e6, 15e6), 'C2':(0.01e6, 5e6), 'C3':(0.01e6, 5e6)}\n",
        "\n",
        "  # Define bayesian optimizer\n",
        "  optimizer = BayesianOptimization(\n",
        "      f=loss,\n",
        "      pbounds=pbounds,\n",
        "      random_state=42\n",
        "      )\n",
        "\n",
        "  # Define bayesian optimizer properties\n",
        "  optimizer.maximize(init_points=5, n_iter=15, acq='ei', xi=1e-2)\n",
        "\n",
        "  print('Best Score: %0.4f' % result.best_score_) # find attribute for best score\n",
        "  print('Best Hyperparameters: %s' % optimizer.max)\n",
        "\n",
        "  #return the best hyperparameters\n",
        "  return optimizer.max"
      ],
      "metadata": {
        "id": "IYE-mo2tji1w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Evaluating Model Performances with Tuned Hyperparameters"
      ],
      "metadata": {
        "id": "ww84d55dkon6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*--> Which metric is going to be used?*"
      ],
      "metadata": {
        "id": "yWjiFss4lU4v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_errors_lr, test_errors_lr = [], []\n",
        "for m in range(1, len(X_lr_train)):\n",
        "  model = model(**result.best_params_)\n",
        "\n",
        "  model.fit(X_lr_train[:m], y_lr_train[:m])\n",
        "\n",
        "  y_lr_train_predict = model_lr.predict(X_lr_train[:m])\n",
        "  y_lr_test_predict = model_lr.predict(X_lr_test)\n",
        "  \n",
        "  train_errors_lr.append(mean_absolute_percentage_error(y_lr_train[:m], y_lr_train_predict))\n",
        "  test_errors_lr.append(mean_absolute_percentage_error(y_lr_test, y_lr_test_predict))\n"
      ],
      "metadata": {
        "id": "512O-N9cm1rn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Visualization\n",
        "\n",
        "Compare the performance of the model different hyperparameter tuning "
      ],
      "metadata": {
        "id": "lKPhXnWcnOpA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*--> Is histogram the best for visualizing?*"
      ],
      "metadata": {
        "id": "Sj9RCaZslg-e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_scores(model, **params):\n",
        "  train_errors, test_errors = [], []\n",
        "\n",
        "  for m in np.linspace(1, len(X_train), len(X_train):\n",
        "\n",
        "    model = model(**params)\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    y_predict_train = model.predict(X_train[:m])\n",
        "    y_predict_test = model.predict(X_test)\n",
        "    \n",
        "    train_errors.append(mean_absolute_percentage_error(y_train[:m], y_predict_train))\n",
        "    test_errors.append(mean_absolute_percentage_error(y_test, y_predict_test))\n",
        "\n",
        "  return train_errors, test_errors "
      ],
      "metadata": {
        "id": "LP_vtpH7pLXH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_learning_curves(train_errors, test_errors):\n",
        "\n",
        "  fig, ax = plt.subplots()\n",
        "\n",
        "  ax.plot(np.linspace(1, len(X_train), len(X_train), train_errors, '-', linewidth=3,\n",
        "          label=\"Training score\")\n",
        "  ax.plot(np.linspace(1, len(X_test), len(X_test), test_errors, '-', linewidth=3,\n",
        "          label=\"Test score\")\n",
        "\n",
        "  ax.xlabel(\"Training Set Size\")\n",
        "  ax.ylabel(\"MAPE\")\n",
        "  ax.legend(loc=\"best\")\n",
        "\n",
        "  return fig"
      ],
      "metadata": {
        "id": "odPgWX01pNzW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "param_list = [ *, * , *, *]\n",
        "\n",
        "for p in param_list:\n",
        "  train_scores, test_scores = get_scores(model, **p)\n",
        "\n",
        "  plot_learning_curves(train_scores, test_scores)"
      ],
      "metadata": {
        "id": "buVRJwN2qX2d"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}